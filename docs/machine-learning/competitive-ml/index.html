<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Competitive Machine Learning · datadocs</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## Goal definition"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Competitive Machine Learning · datadocs"/><meta property="og:type" content="website"/><meta property="og:url" content="https://polakowo.github.io/datadocs/"/><meta property="og:description" content="## Goal definition"/><meta property="og:image" content="https://polakowo.github.io/datadocs/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://polakowo.github.io/datadocs/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/datadocs/img/favicon.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-142521178-1"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'UA-142521178-1');
            </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/datadocs/js/code-block-buttons.js"></script><script type="text/javascript" src="/datadocs/js/disqus.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/datadocs/js/scrollSpy.js"></script><link rel="stylesheet" href="/datadocs/css/prism.css"/><link rel="stylesheet" href="/datadocs/css/main.css"/><script src="/datadocs/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/datadocs/"><h2 class="headerTitle">datadocs</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/datadocs/docs/machine-learning/linear-models" target="_self">Docs</a></li><li class=""><a href="https://github.com/polakowo/datadocs" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Competitions</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Machine Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/machine-learning">Machine Learning</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Methods</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/linear-models">Linear Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/tree-based-models">Tree-Based Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/ensemble-methods">Ensemble Methods</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Features</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/eda">Exploratory Data Analysis</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/feature-engineering">Feature Engineering</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/advanced-features">Advanced Features</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Optimization</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/metric-optimization">Metric Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/validation-schemes">Validation Schemes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/hyperopt">Hyperparameter Optimization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Competitions</h4><ul><li class="navListItem navListItemActive"><a class="navItem" href="/datadocs/docs/machine-learning/competitive-ml">Competitive Machine Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/data-leakages">Data Leakages</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Production</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/production-code">Production Code</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/deployment">Deployment</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/deployment-to-cloud">Deployment to Cloud</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Deep Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/deep-learning">Deep Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/dl-strategy">Deep Learning Strategy</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Fundamentals</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/backpropagation">Backpropagation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/activation-functions">Activation Functions</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/initialization">Initialization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/optimization">Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/regularization">Regularization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Computer Vision</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnns">Convolutional Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnn-architectures">CNN Architectures</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/object-detection">Object Detection</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/face-recognition">Face Recognition</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nst">Neural Style Transfer</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Natural Language Processing</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/rnns">Recurrect Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/word-embeddings">Word Embeddings</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nmt">Neural Machine Translation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/attention-mechanism">Attention Mechanism</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/speech-recognition">Speech Recognition</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Big Data<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-engineering">Data Engineering</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-warehouses">Data Warehouses</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-lakes">Data Lakes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-pipelines">Data Pipelines</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/cloud-computing">Cloud Computing</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Databases</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/database-design">Database Design</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/sql-databases">SQL Databases</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/wide-column-stores">Wide Column Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/key-value-stores">Key Value Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/document-stores">Document Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/graph-stores">Graph Stores</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Hadoop</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/hadoop">Hadoop Ecosystem</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-ingestion">Data Ingestion</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-storage">Data Storage</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-processing">Data Processing</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/query-engines">Query Engines</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/cluster-management">Cluster Management</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/polakowo/datadocs/edit/master/docs/machine-learning/competitive-ml.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 class="postHeaderTitle">Competitive Machine Learning</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="goal-definition"></a><a href="#goal-definition" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Goal definition</h2>
<ul>
<li>To learn more about an interesting problem:
<ul>
<li>You may want the competition to have a wide discussion on the forums.</li>
<li>For example, if you are interested in data science with application to medicine, try to predict <a href="https://www.kaggle.com/c/data-science-bowl-2017">lung cancer in the Data Science Bowl 2017</a> or <a href="(https://www.kaggle.com/c/melbourne-university-seizure-prediction)">seizures in long-term human intracranial EEG recordings</a>.</li>
</ul></li>
<li>To get acquainted with new software tools:
<ul>
<li>You may want the competition to have required tutorials.</li>
<li>For example, if you want to learn a neural networks library, choose any of the competitions with images like the <a href="https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring">The Nature Conservancy Fisheries Monitoring Competition</a> or <a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space">Planet: Understanding the Amazon from Space</a>.</li>
</ul></li>
<li>To hunt for a medal:
<ul>
<li>Check how many submissions do participants have.</li>
<li>If the points that people have over hundred submissions, it can be a clear sign of inconsistency of local validation and leaderboard scores.</li>
<li>On the other hand, if there are people with few submissions in the top, that usually means there should be a non-trivial approach to this competition or it's discovered only by few people.</li>
<li>If leaderboard mostly consists of teams with only one participant, you'll probably have enough chances if you gather a good team.</li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="research-papers"></a><a href="#research-papers" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Research papers</h4>
<ul>
<li>Read scientific articles on the topic of the competition.</li>
<li>This can get you ideas about ML-related things (for example, how to optimize AUC).</li>
<li>Way to get familiar with problem domain (especially useful for feature generation).</li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="past-solutions"></a><a href="#past-solutions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Past solutions</h4>
<ul>
<li><a href="http://ndres.me/kaggle-past-solutions/">http://ndres.me/kaggle-past-solutions/</a></li>
<li><a href="https://www.kaggle.com/wiki/PastSolutions">https://www.kaggle.com/wiki/PastSolutions</a></li>
<li><a href="http://www.chioka.in/kaggle-competition-solutions/">http://www.chioka.in/kaggle-competition-solutions/</a></li>
<li><a href="https://github.com/ShuaiW/kaggle-classification/">https://github.com/ShuaiW/kaggle-classification/</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="pipeline"></a><a href="#pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pipeline</h2>
<ul>
<li>Never join a competition at its very beginning:
<ul>
<li>It happens that a competition starts and someone finds a bug in the data.</li>
</ul></li>
<li>Understand the problem:
<ul>
<li>Type of problem?</li>
<li>How BIG is data (what computational resources do you need)?</li>
<li>What is the metric is being testing on? Find a similar competition.</li>
</ul></li>
<li>Start with a quick EDA:
<ul>
<li>Check the data for leakages (and discrepancies between train and test).</li>
<li>Plot features versus the target variable and time (if available).</li>
<li>Consider univariate predictability metrics (IV, R, AUC).</li>
<li>Binning numerical features and correlation matrices.</li>
</ul></li>
<li>Build a simple (or even primitive) baseline:
<ul>
<li>Often you can find baseline solutions provided by organizers or in kernels.</li>
<li>Start rather with RF than with GBMs.</li>
<li>At least Random Forest works quite fast and requires almost no tuning of hyperparameters.</li>
</ul></li>
<li>Decide on the correct cross-validation scheme:
<ul>
<li><em>People have won just by selecting the right way to validate.</em></li>
<li>Is time important? Time-based validation.</li>
<li>New entities in test? Stratified validation.</li>
<li>Otherwise random K-fold strategy.</li>
<li>Check if validation is stable (i.e. correlates with public LB score).</li>
</ul></li>
<li>Debug the full pipeline:
<ul>
<li>From loading data to writing a submission file.</li>
</ul></li>
<li>After trying the problem individually, explore the public kernels and forums:
<ul>
<li>Other participants have different approaches resulting in diversity.</li>
</ul></li>
<li>Proceed from simple to complex:
<ul>
<li>Add features in bulks (create many features at once).</li>
</ul></li>
<li>Perform hyperparameter tuning:
<ul>
<li>When tuning parameters, first try to make the model to overfit.</li>
</ul></li>
<li>Perform ensembling:
<ul>
<li>Proceed with ensembling only after feature engineering is done.</li>
</ul></li>
<li>Select the best on LB and the best submission locally (or the most diverse one).</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="working-with-ideas"></a><a href="#working-with-ideas" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Working with ideas</h3>
<ul>
<li>Organize ideas in some structure:
<ul>
<li>What things could work here? What approaches you may want to take?</li>
</ul></li>
<li>After you're done, read forums and highlight interesting posts and topics.</li>
<li>Sort ideas into priority order. Most important and promising needs to be implemented first.</li>
<li>Or you may want to organize these ideas into topics.
<ul>
<li>Ideas about feature generation, validation, metric optimization.</li>
</ul></li>
<li>Now pick up an idea and implement it.</li>
<li>Try to understand the reasons why something works or not.
<ul>
<li>Is there some hidden data structure we didn't notice before? The ability to analyze the work and derive conclusions will get you on the right track to reveal hidden data patterns and leaks.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="data-loading"></a><a href="#data-loading" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data loading</h3>
<ul>
<li>Pay attention to optimal usage of computational resources to save a lot of time later.</li>
<li>Running an experiment often requires a lot of kernel restarts which leads to reloading data:
<ul>
<li>Do basic preprocessing and convert <em>csv</em> files into <em>hdf5</em> (<code>pandas</code>) or <em>npy</em> (<code>numpy</code>) for faster loading.</li>
</ul></li>
<li>Do not forget that by default data is stored in 64-bit format:
<ul>
<li>Most of times you can safely downcast it to 32 bits. This will result in a 2-fold memory saving.</li>
</ul></li>
<li>Large datasets can be processed in chunks with <code>pandas</code>.</li>
<li>Handling big categories:
<ul>
<li>Split the dataset by a category and unload to separate files.</li>
<li>Allows performing feature engineering on each category separately.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="feature-engineering"></a><a href="#feature-engineering" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Feature engineering</h3>
<ul>
<li>The type of problem defines the type of feature engineering:
<ul>
<li>Image classification: Scaling, resizing, smoothing, data augmentation (<a href="https://www.kaggle.com/c/data-science-bowl-2018">Previous Data Science Bowls</a>)</li>
<li>Sound classification: Fourier transform, MFCC, spectograms, scaling (<a href="https://www.kaggle.com/c/tensorflow-speech-recognition-challenge">TensorFlow Speech Recognition Challenge</a>)</li>
<li>Text classification: N-grams, TF-IDF, SVD, text preprocessing, hashing (<a href="https://www.kaggle.com/c/stumbleupon/data">StumbleUpon Evergreen Classification Challenge</a>)</li>
<li>Time series: Lags, smoothing, derivatives, outlier removal (<a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting">Walmart Recruiting - Store Sales Forecasting</a>)</li>
<li>Categorical features: Encodings (<a href="https://www.kaggle.com/c/amazon-employee-access-challenge/data">Amazon.com - Employee Access Challenge</a>)</li>
<li>Numeric features: Scaling, binning, outlier removal, dimensionality reduction, univariate transformations (<a href="https://www.kaggle.com/c/afsis-soil-properties">Africa Soil Property Prediction</a>)</li>
<li>Feature interactions: Multiplication, division (<a href="https://www.kaggle.com/c/homesite-quote-conversion">Homesite Quote Conversion</a>)</li>
<li>Recommenders: Transactional history, item popularity, frequency of purchase (<a href="https://www.kaggle.com/c/acquire-valued-shoppers-challenge/leaderboard">Acquire Valued Shoppers Challenge</a>)</li>
</ul></li>
<li>This process can be automated using selection with cross validation.
<ul>
<li>As long as your CV strategy is consistent, time and scalability are the only factors here.</li>
</ul></li>
<li>Feature selection techniques:
<ul>
<li>Forward: Start from the null model, add one feature at a time and check the CV accuracy.</li>
<li>Backward: Start from the full model and remove variables one by one.</li>
<li>Mixed: Use a mix of above techniques.</li>
<li>Use permutations.</li>
<li>Use feature importances from RFs and GBMs.</li>
<li>Apply some statistical tests.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="modeling"></a><a href="#modeling" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Modeling</h3>
<ul>
<li>For tabular datasets GBMs work best, while for unstructured data DL work better.</li>
<li>The type of problem defines the type of modeling:
<ul>
<li>Image classification: CNNs</li>
<li>Sound classification: CNNs (CRNN), LSTMs</li>
<li>Text classification: Linear models, RNNs, Transformers, Factorization machines</li>
<li>Time series: Autoregressive models, LSTMs</li>
<li>Categorical features: GBMs, Linear models, NNs, Factorization machines</li>
<li>Numeric features: GBMs, Linear models, NNs, SVMs</li>
<li>Interactions: GBMs, Linear models, NNs</li>
<li>Recommenders: GBMs, Collaborative filtering, NNs, Factorization machines</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="evaluation"></a><a href="#evaluation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Evaluation</h3>
<ul>
<li>Extensive evaluation is not always needed:
<ul>
<li>Even for medium-sized datasets like 100,000 rows you can validate your models with a simple holdout strategy.</li>
</ul></li>
<li>Switch to CV only when it is really required:
<ul>
<li>For example, when you've already hit some limits and can move forward only with some marginal improvements.</li>
</ul></li>
<li>Faster evaluation:
<ul>
<li>Start with fastest models like LightGBM.</li>
<li>Use early stopping to reduce the run time.</li>
<li>Switch to tuning the models and ensembling only when you are satisfied with feature engineering.</li>
<li>Rent a larger server if you're uncomfortable with your computational resources.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="ensembling"></a><a href="#ensembling" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Ensembling</h3>
<ul>
<li>Save predictions on internal validation and test sets.
<ul>
<li>From all the models trained before, make sure you save their predictions.</li>
<li><em>Sometimes team collaboration is just sending csv files.</em></li>
</ul></li>
<li>Different ways to combine from averaging to stacking:
<ul>
<li>Small data requires simpler ensembling techniques.</li>
<li>Average a few low-correlated predictions with good scores.</li>
</ul></li>
<li>The stacking process requires its own feature engineering.</li>
<li>Most of the times ensembling leads only to a marginal score improvement.</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="code-organization"></a><a href="#code-organization" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code organization</h2>
<ul>
<li>Set up a separate environment for each competition.</li>
<li>If your code is hard to read, you will definitely have problems sooner or later:
<ul>
<li>Keep important code clean.</li>
<li>Use good variable and function names.</li>
</ul></li>
<li>Keep your research reproducible:
<ul>
<li>Fix all random seeds.</li>
<li>Write down exactly how any of the features were generated.</li>
<li>Store the code under a version control system like git.</li>
<li>You may also create a notebook for each submission so they can be compared later.</li>
</ul></li>
<li>Reuse code as much as possible:
<ul>
<li>Especially important to use the same code for train and test stages. For example, features should be prepared and transformed by the same code in order to guarantee that they're produced in a consistent manner.</li>
<li>Move reusable code into separate functions or even separate modules.</li>
<li>We are provided with training and test CSV files (<em>train.csv</em> and <em>test.csv</em>). Split the training set to training and holdout sets, and save those to disk as CSV files with the same structure as input files (<em>train.csv</em> and <em>valid.csv</em>). Then it only takes you to switch the paths to either experiment or produce a submission.</li>
<li>Use a custom library with frequent operations already implemented.
<ul>
<li><a href="https://github.com/Far0n/kaggletils">Far0n's framework for Kaggle competitions &quot;kaggletils&quot;</a></li>
</ul></li>
</ul></li>
<li>Long execution history leads to lots of globally-defined variables:
<ul>
<li>Restart the notebook from time to time.</li>
</ul></li>
<li>Don't pay too much attention to the code quality when experimenting:
<ul>
<li>It's okay to have ugly code unless you don't use it for submission.</li>
<li>Try focusing entirely on data and google domain-specific knowledge.</li>
</ul></li>
<li>Split EDA and model training into separate notebooks.</li>
<li>Use macros for frequent code.
<ul>
<li><a href="https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/">28 Jupyter Notebook tips, tricks and shortcuts</a></li>
</ul></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="collaboration"></a><a href="#collaboration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Collaboration</h2>
<ul>
<li>Advantages:
<ul>
<li>Collaboration makes more fun.</li>
<li>You learn more by sharing knowledge with other participants.</li>
<li>You score better because you cover more ground and solutions are more diverse.</li>
</ul></li>
<li>Start collaborating after getting some experience (2-3 competitions)</li>
<li>Start with people around your rank.</li>
<li>Make solutions uncorrelated:
<ul>
<li>Do not overdiscuss things.</li>
<li>Collaborate with people who have different backgrounds.</li>
</ul></li>
</ul>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 2019-6-20 by Oleg Polakow</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/datadocs/docs/machine-learning/hyperopt"><span class="arrow-prev">← </span><span>Hyperparameter Optimization</span></a><a class="docs-next button" href="/datadocs/docs/machine-learning/data-leakages"><span>Data Leakages</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#goal-definition">Goal definition</a></li><li><a href="#pipeline">Pipeline</a><ul class="toc-headings"><li><a href="#working-with-ideas">Working with ideas</a></li><li><a href="#data-loading">Data loading</a></li><li><a href="#feature-engineering">Feature engineering</a></li><li><a href="#modeling">Modeling</a></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#ensembling">Ensembling</a></li></ul></li><li><a href="#code-organization">Code organization</a></li><li><a href="#collaboration">Collaboration</a></li></ul></nav></div><footer class="nav-footer" id="footer"><div class="brand-box"><div class="brand"><a href="https://www.tum.de/nc/en/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/tum_logo.png" alt="Technical University of Munich" height="45"/></a></div><div class="brand"><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a></div></div><section class="copyright">Copyright © 2019 polakowo.io</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '6642fca03d716a543ac4428d7d20b842',
                indexName: 'polakowo-datadocs',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>