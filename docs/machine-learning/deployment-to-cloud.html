<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Deployment to Cloud · datadocs</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="- Cloud services like Amazon’s SageMaker can be used for all parts of the ML workflow."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Deployment to Cloud · datadocs"/><meta property="og:type" content="website"/><meta property="og:url" content="https://polakowo.github.io/datadocs/"/><meta property="og:description" content="- Cloud services like Amazon’s SageMaker can be used for all parts of the ML workflow."/><meta property="og:image" content="https://polakowo.github.io/datadocs/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://polakowo.github.io/datadocs/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/datadocs/img/favicon.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-142521178-1"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'UA-142521178-1');
            </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/datadocs/js/code-block-buttons.js"></script><script type="text/javascript" src="/datadocs/js/disqus.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/datadocs/js/scrollSpy.js"></script><link rel="stylesheet" href="/datadocs/css/prism.css"/><link rel="stylesheet" href="/datadocs/css/main.css"/><script src="/datadocs/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/datadocs/"><h2 class="headerTitle">datadocs</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/datadocs/docs/machine-learning/linear-models" target="_self">Docs</a></li><li class=""><a href="https://github.com/polakowo/datadocs" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Production</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Machine Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/machine-learning">Machine Learning</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Methods</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/linear-models">Linear Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/tree-based-models">Tree-Based Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/ensemble-methods">Ensemble Methods</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Features</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/eda">Exploratory Data Analysis</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/feature-engineering">Feature Engineering</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/advanced-features">Advanced Features</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Optimization</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/metric-optimization">Metric Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/validation-schemes">Validation Schemes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/hyperopt">Hyperparameter Optimization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Competitions</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/competitive-ml">Competitive Machine Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/data-leakages">Data Leakages</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Production</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/production-code">Production Code</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/deployment">Deployment</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/datadocs/docs/machine-learning/deployment-to-cloud">Deployment to Cloud</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Deep Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/deep-learning">Deep Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/dl-strategy">Deep Learning Strategy</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Fundamentals</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/backpropagation">Backpropagation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/activation-functions">Activation Functions</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/initialization">Initialization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/optimization">Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/regularization">Regularization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Computer Vision</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnns">Convolutional Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnn-architectures">CNN Architectures</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/object-detection">Object Detection</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/face-recognition">Face Recognition</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nst">Neural Style Transfer</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Natural Language Processing</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/rnns">Recurrect Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/word-embeddings">Word Embeddings</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nmt">Neural Machine Translation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/attention-mechanisms">Attention Mechanisms</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/speech-recognition">Speech Recognition</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Big Data<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-engineering">Data Engineering</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-warehouses">Data Warehouses</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-lakes">Data Lakes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-pipelines">Data Pipelines</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/cloud-computing">Cloud Computing</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Databases</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/database-design">Database Design</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/sql-databases">SQL Databases</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/wide-column-stores">Wide Column Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/key-value-stores">Key Value Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/document-stores">Document Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/graph-stores">Graph Stores</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Hadoop</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/hadoop">Hadoop Ecosystem</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-ingestion">Data Ingestion</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-storage">Data Storage</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-processing">Data Processing</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/query-engines">Query Engines</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/cluster-management">Cluster Management</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/polakowo/datadocs/edit/master/docs/machine-learning/deployment-to-cloud.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 class="postHeaderTitle">Deployment to Cloud</h1></header><article><div><span><ul>
<li>Cloud services like Amazon’s SageMaker can be used for all parts of the ML workflow.</li>
<li>Cloud services like Google’s Cloud ML Engine are meant to be used primarily for modeling and deployment.</li>
<li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-mlconcepts.html">Machine Learning with Amazon SageMaker</a></li>
<li><a href="https://cloud.google.com/ml-engine/docs/ml-solutions-overview">Machine learning workflow</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml">What is Azure Machine Learning service?</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="amazon-sagemaker"></a><a href="#amazon-sagemaker" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Amazon SageMaker</h2>
<p><center><img width=120 src="/datadocs/assets/IconOnly-1.png"/></center></p>
<ul>
<li><a href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a> is a fully-managed, end-to-end machine learning service.</li>
<li>Compared to plug-and-play API services, SageMaker is a platform tailor-made for ML workflows.
<ul>
<li>Covers the entire ML workflow to label and prepare data, choose an algorithm, train the model, tune and optimize it for deployment, make predictions, and take action.</li>
</ul></li>
<li>Habitual environment:
<ul>
<li>Offers Python and Jupyter notebook environments.</li>
</ul></li>
<li>Provides common ML algorithms, along with other tools, to simplify and accelerate the ML workflow.
<ul>
<li>Provides out-of-the-box solution for quick model training.</li>
<li>Allows using custom algorithms.</li>
<li>Provides a range of algorithms that can be subscribed to from AWS Marketplace.</li>
<li>Provides Apache Spark for data pre-processing.</li>
<li>Allows packaging any ML algorithm into a Docker container and plug it in.</li>
<li><a href="https://github.com/awslabs/amazon-sagemaker-examples">Amazon SageMaker Examples</a></li>
</ul></li>
<li>“Zero-configuration” workflow for training:
<ul>
<li>No special configuration is required to start training some model remotely in the cloud.</li>
<li>One can choose from a single general-purpose instance to a distributed cluster of GPU instances.</li>
</ul></li>
<li>Out-of-the-box support for multi-node training.</li>
<li>Straightforward deployment of trained models to production.</li>
<li>A developer can track and trigger alarms for changes in performance via Amazon CloudWatch.</li>
<li>SageMaker is a valuable skill to learn:
<ul>
<li>Teaches the best practices in the world of machine learning.</li>
<li>Guides through the machine learning lifecycle.</li>
<li>Has a repository with use cases updated continuously.</li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="apis"></a><a href="#apis" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>APIs</h4>
<ul>
<li>High level functionality:
<ul>
<li>Certain choices have been made on the user's behalf.</li>
<li>Makes development much quicker.</li>
</ul></li>
<li>Low level functionality:
<ul>
<li>Requires knowing each of the objects involved in the SageMaker environment.</li>
<li>Benefits from allowing the user a great deal of flexibility.</li>
</ul></li>
<li><a href="https://sagemaker.readthedocs.io/en/latest/">Python SDK Documentation</a></li>
<li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/">Developer Documentation</a></li>
<li>Search for code definitions in <a href="https://github.com/aws/sagemaker-python-sdk">Python SDK Code</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="workflow"></a><a href="#workflow" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Workflow</h3>
<h4><a class="anchor" aria-hidden="true" id="create-an-amazon-s3-bucket"></a><a href="#create-an-amazon-s3-bucket" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create an Amazon S3 bucket</h4>
<ul>
<li>Amazon S3 is used as a central storage service when using SageMaker.</li>
<li>Data (also results, checkpoints, logs, etc.) must then be stored in S3 object storage.
<ul>
<li>Create a dedicated S3 bucket for a single project.</li>
</ul></li>
<li>There is no practical limit to the size of the data set.
<ul>
<li>But it takes around 20 minutes to download 100Gb worth of images to a training instance.</li>
<li>Thus, do all the preliminary trials and polish the model elsewhere.</li>
</ul></li>
<li>S3 bucket must be in the same region as the training job.</li>
<li>One can create a default bucket with <code>sess.default_bucket()</code></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="create-a-notebook-instance"></a><a href="#create-a-notebook-instance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create a notebook instance</h4>
<ul>
<li>Notebook Instances provide a convenient place to process and explore data in addition to making it very easy to interact with the rest of SageMaker's features.</li>
<li>The notebook instances are fully-managed - they are not listed in the console.</li>
<li>Pro tips:
<ul>
<li>Pick the right family, size and version of the EC2 instance.</li>
<li>Pick the right EBS volume (a bit more than the training data, folder <code>~/SageMaker</code>)</li>
<li>Add or create a git repository for collaboration.</li>
<li>Configure security settings (encryption, internet access)</li>
<li>Use a lifecycle config (running a bash script every time you start, also in background)</li>
<li>Elastic inference: Optionally attach a portion of a GPU for local inference.</li>
<li>Use lambda for stopping, resize on the fly, and use <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing</a></li>
<li><a href="https://youtu.be/uQc8Itd4UTs">Fully-Managed Notebook Instances</a></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="build-the-dataset"></a><a href="#build-the-dataset" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Build the dataset</h4>
<ul>
<li>Having large amounts of training data could be a differentiator in building high-quality models.</li>
<li>Use <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html">Amazon SageMaker Ground Truth</a> to create a labeled dataset.
<ul>
<li>Uses a combination of human labelers and an active learning model to label data.</li>
</ul></li>
<li>Human labelers:
<ul>
<li>Workers from Amazon Mechanical Turk, a vendor company, or an internal, private workforce.</li>
<li>Bounding boxes, image and text classification, semantic segmentation, named entity recognition.</li>
</ul></li>
<li>Active learning model:
<ul>
<li>An ML algorithm decides which data needs to be labeled by humans.</li>
<li>Labels data points and sends those with a confidence below a threshold to human workers.</li>
<li>Reduces the time and cost to label datasets by about 70%.</li>
</ul></li>
<li>Increase the quality by increasing the number of labelers per dataset object.
<ul>
<li>Use majority voting or probabilities of labelers being correct by looking at their past work.</li>
</ul></li>
<li><a href="https://youtu.be/oQOQ8nvgu1w">Build Highly Accurate Training Datasets at Reduced Costs</a></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="explore-and-transform-the-data"></a><a href="#explore-and-transform-the-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Explore and transform the data</h4>
<ul>
<li>Explore training data to determine what to clean up and which transformations to apply.</li>
<li>Split the training dataset into training and validation.</li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Split into train, validation and test</span>

X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=<span class="hljs-number">0.33</span>)
X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train, y_train, test_size=<span class="hljs-number">0.33</span>)
</code></pre>
<ul>
<li>Save the datasets into files and upload them to S3.
<ul>
<li>Do the same with test to use SageMaker's Batch Transform functionality to test the model.</li>
<li>The datasets should contain no headers or index, the label should occur as first column.</li>
<li>Also upload all artifacts that are required by inference code (e.g. word vocabulary)</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Upload training data to S3</span>

pd.concat([y_train, X_train], axis=<span class="hljs-number">1</span>).to_csv(os.path.join(data_dir, <span class="hljs-string">'train.csv'</span>), header=<span class="hljs-literal">False</span>, index=<span class="hljs-literal">False</span>)
train_location = session.upload_data(os.path.join(data_dir, <span class="hljs-string">'train.csv'</span>), key_prefix=prefix)

</code></pre>
<ul>
<li>One can transform them into <code>RecordSet</code> format to do this automatically.</li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Create training RecordSet</span>

X_train_np = X_train.astype(<span class="hljs-string">'float32'</span>)
y_train_np = y_train.astype(<span class="hljs-string">'float32'</span>)
formatted_train_data = learner.record_set(X_train_np, labels=y_train_np)
</code></pre>
<ul>
<li>Think of ETL as a software application.
<ul>
<li>Wrap steps into modular, readable, reusable functions.</li>
</ul></li>
<li>Inference pipelines:
<ul>
<li>Deploy up to 5 containers as a pipeline model (<code>PipelineModel</code>)</li>
<li>For example, pre-process -&gt; PCA -&gt; XGBoost -&gt; post-process.</li>
<li>They will run in serial and co-located on the same EC2 instance.</li>
<li>This is one way to productionize the ETL code.</li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="build-the-model"></a><a href="#build-the-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Build the model</h4>
<ul>
<li>Models are essentially a combination of model artifacts formed during a training job (such as weights) and an associated Docker container (code) that is used to perform inference.</li>
<li>SageMaker uses managed Docker containers when running scripts, training algorithms or deploying models.
<ul>
<li>Hosted on Amazon ECR, versioned, and can be modified and extended easily.</li>
<li>Enable endpoints, batch transform, and inference pipelines by design.</li>
<li>Can be developed and run locally for testing.</li>
</ul></li>
<li><a href="https://youtu.be/yGc0qePSYig">Built-in Machine Learning Algorithms</a></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Built-in estimator</span>

container = get_image_uri(session.boto_region_name, <span class="hljs-string">'xgboost'</span>)
xgb = sagemaker.estimator.Estimator(container,
                                    role,
                                    train_instance_count=<span class="hljs-number">1</span>,
                                    train_instance_type=<span class="hljs-string">'ml.m4.xlarge'</span>,
                                    output_path=<span class="hljs-string">'s3://{}/{}/output'</span>.format(session.default_bucket(), prefix),
                                    sagemaker_session=session)
</code></pre>
<ul>
<li>Bring own script, algorithm or model:
<ul>
<li>Script mode: Quick training but limited options.</li>
<li>Custom container: Most flexible but more time consuming to develop.</li>
<li>Marketplace: Easy to add value quickly but less insight into solution.</li>
<li><a href="https://youtu.be/YQyid2uLOvI">Bring Your Own Custom ML Models</a></li>
<li><a href="https://www.youtube.com/watch?v=VeEGAeohe7c&amp;list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz&amp;index=8">Use the Deep Learning Framework of Your Choice</a></li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Custom sklearn estimator</span>

<span class="hljs-keyword">from</span> sagemaker.sklearn.estimator <span class="hljs-keyword">import</span> SKLearn

sklearn_estimator = SKLearn(entry_point=<span class="hljs-string">'train.py'</span>, 
                            source_dir=<span class="hljs-string">'source_sklearn'</span>, 
                            role=role, 
                            train_instance_count=<span class="hljs-number">1</span>, 
                            train_instance_type=<span class="hljs-string">'ml.c5.xlarge'</span>, 
                            sagemaker_session=sagemaker_session, 
                            hyperparameters={},
                            output_path=<span class="hljs-string">'s3://{}/{}/output'</span>.format(bucket, prefix))
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="train-and-evaluate-the-model"></a><a href="#train-and-evaluate-the-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Train and evaluate the model</h4>
<ul>
<li>Before starting a training job, ensure that the model behaves correctly (locally, on a subset of data)</li>
<li>Training Jobs allow us to create model artifacts by fitting various machine learning models to data.
<ul>
<li>SageMaker spins up one or several “training instances”, copies all the necessary scripts and data from S3 there, runs the training, and uploads the model back to S3.</li>
<li>Every model run on a training job has its own ephemeral (short-lived) EC2 cluster.</li>
<li>No more virtual environments, conflicting package installations, and resource dependencies.</li>
<li>The cluster comes down immediately after the model finished training.</li>
<li>The logs are sent to CloudWatch and can be monitored via console or notification system.</li>
</ul></li>
<li>A training job requires input and output S3 locations, Docker container location, and EC2 configuration.</li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Fit the estimator</span>

s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type=<span class="hljs-string">'csv'</span>)
s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type=<span class="hljs-string">'csv'</span>)

xgb.fit({<span class="hljs-string">'train'</span>: s3_input_train, <span class="hljs-string">'validation'</span>: s3_input_validation})
</code></pre>
<ul>
<li>Distributed training:
<ul>
<li><a href="https://hub.packtpub.com/horovod-an-open-source-distributed-training-framework-by-uber-for-tensorflow-keras-pytorch-and-mxnet/">Horovod</a> enables running multiple processes per node (multi-GPU training)</li>
<li>Use production-ready, infinitely scalable algorithms that support data streaming.</li>
<li>Use incremental training (resume a previous training job) to save both time and resources.</li>
<li><a href="https://www.youtube.com/watch?v=CDg55-GkIm4&amp;list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz&amp;index=7">Scale up Training of Your ML Models with Distributed Training</a></li>
</ul></li>
<li>Pro tips:
<ul>
<li>Read white papers, always put label into the 1st column, and tune hyperparameters.</li>
<li>Use examples provided by Amazon, pipe mode for streaming data from S3, and incremental training.</li>
<li>Use SageMaker Search to compare results of previous jobs.</li>
<li>Run training jobs in parallel from the notebook.</li>
<li>Soft limit the number of EC2 instances used for training job.</li>
<li>Do local sanity checks before starting a training job.</li>
<li><a href="https://youtu.be/Xph2ajPEDPQ">Train Your ML Models Accurately</a></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="tune-hyperparameters"></a><a href="#tune-hyperparameters" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tune hyperparameters</h4>
<ul>
<li>Hyperparameter Tuning allows us to create multiple training jobs each with different hyperparameters in order to find the hyperparameters that work best for a given problem.</li>
<li>SageMaker provides an automated way of doing hyperparameter tuning.
<ul>
<li>One tuning job is just an umbrella over multiple training jobs.</li>
<li>One can specify the maximum number of training jobs and parallel training jobs.</li>
<li>SageMaker then provides the name of the best-performing job based on the objective metric.</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Hyperparameter tuning</span>

<span class="hljs-keyword">from</span> sagemaker.tuner <span class="hljs-keyword">import</span> IntegerParameter, ContinuousParameter, HyperparameterTuner

<span class="hljs-comment"># Make sure to set any model specific hyperparameters that we wish to have default values</span>
xgb.set_hyperparameters(max_depth=<span class="hljs-number">5</span>,
                        eta=<span class="hljs-number">0.2</span>,
                        gamma=<span class="hljs-number">4</span>,
                        min_child_weight=<span class="hljs-number">6</span>,
                        subsample=<span class="hljs-number">0.8</span>,
                        objective=<span class="hljs-string">'reg:linear'</span>,
                        early_stopping_rounds=<span class="hljs-number">10</span>,
                        num_round=<span class="hljs-number">200</span>)

<span class="hljs-comment"># Create the hyperparameter tuner</span>
xgb_tuner = HyperparameterTuner(estimator=xgb,
                                objective_metric_name=<span class="hljs-string">'validation:rmse'</span>,
                                objective_type=<span class="hljs-string">'Minimize'</span>,
                                max_jobs=<span class="hljs-number">20</span>,
                                max_parallel_jobs=<span class="hljs-number">3</span>,
                                hyperparameter_ranges={
                                    <span class="hljs-string">'max_depth'</span>: IntegerParameter(<span class="hljs-number">3</span>, <span class="hljs-number">12</span>),
                                    <span class="hljs-string">'eta'</span>: ContinuousParameter(<span class="hljs-number">0.05</span>, <span class="hljs-number">0.5</span>),
                                    <span class="hljs-string">'min_child_weight'</span>: IntegerParameter(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>),
                                    <span class="hljs-string">'subsample'</span>: ContinuousParameter(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.9</span>),
                                    <span class="hljs-string">'gamma'</span>: ContinuousParameter(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>),
                                })
</code></pre>
<ul>
<li>Each notebook is self contained, that is, models cannot be shared between them.
<ul>
<li>But one can use <code>attach</code> method to create an Estimator object which is attached to an already completed training job (only the name of the job required)</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py">xgb_attached = sagemaker.estimator.Estimator.attach(xgb_tuner.best_training_job())
</code></pre>
<ul>
<li>CloudWatch provides a UI through which we can examine various logs generated during training.
<ul>
<li>This can be especially useful when diagnosing errors.</li>
</ul></li>
<li>Pro tips:
<ul>
<li>Use Bayesian optimization for efficiency, or random search for full parallelism.</li>
<li>Use <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html">warm start</a>: take the previous evaluations as a starting point (reduces the search space)</li>
<li>Use transfer learning: permits changing the search space, algorithm image or dataset.</li>
<li>Check docs on which hyperparameters are valid for tuning.</li>
<li><a href="https://youtu.be/xpZFNIOaQns">Tune Your ML Models to the Highest Accuracy</a></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="test-the-model"></a><a href="#test-the-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test the model</h4>
<ul>
<li>Use SageMaker's Batch Transform functionality to perform inference on a large dataset.
<ul>
<li>SageMaker initializes compute instances and distributes the workload between them.</li>
<li>Enables running inference without a need of a persistent endpoint.</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Batch transform on test set</span>

xgb_transformer = xgb_attached.transformer(instance_count=<span class="hljs-number">1</span>, instance_type=<span class="hljs-string">'ml.m4.xlarge'</span>)
xgb_transformer.transform(test_location, content_type=<span class="hljs-string">'text/csv'</span>, split_type=<span class="hljs-string">'Line'</span>)
xgb_transformer.wait()
!aws s3 cp --recursive $xgb_transformer.output_path $data_dir
test_pred = pd.read_csv(os.path.join(data_dir, <span class="hljs-string">'test.csv.out'</span>), header=<span class="hljs-literal">None</span>)
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="deploy-the-model"></a><a href="#deploy-the-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deploy the model</h4>
<ul>
<li>Deploy the trained model to a production-ready cluster.
<ul>
<li>Integrate endpoints into internet-facing applications.</li>
<li>Monitor the inferences, collect &quot;ground truth,&quot; and evaluate the model to identify drift.</li>
<li>Scale and manage the production environment.</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Deploy the model</span>

xgb_predictor = xgb.deploy(initial_instance_count=<span class="hljs-number">1</span>, instance_type=<span class="hljs-string">'ml.m4.xlarge'</span>)
</code></pre>
<ul>
<li>To get inferences for an entire dataset, use Amazon SageMaker batch transform.
<ul>
<li>Enables preprocessing of and getting inferences from large datasets.</li>
<li>Enables serving predictions on a schedule (event trigger -&gt; Lambda -&gt; S3 -&gt; SageMaker)</li>
<li>Similar to an endpoint, operates with RESTful API.</li>
</ul></li>
<li>To get one inference at a time in real time, set up a persistent endpoint.
<ul>
<li>Allows to perform inference on small amounts of data by sending it bit by bit.</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Predict on test set using endpoint</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(data, rows=<span class="hljs-number">512</span>)</span>:</span>
    <span class="hljs-comment"># We split the data into chunks and send each chunk seperately, accumulating the results.</span>
    split_array = np.array_split(data, int(data.shape[<span class="hljs-number">0</span>] / float(rows) + <span class="hljs-number">1</span>))
    predictions = np.array([])
    <span class="hljs-keyword">for</span> array <span class="hljs-keyword">in</span> split_array:
        predictions = np.append(predictions, predictor.predict(array))
    <span class="hljs-keyword">return</span> predictions

predictions = predict(X_test.values)
</code></pre>
<ul>
<li>Endpoints are the actual HTTP URLs that are created by SageMaker.
<ul>
<li>SageMaker launches a compute instance running a Docker container with the inference code and a URL that data can be sent to and returned from.</li>
<li>So, if you are no longer using a deployed endpoint, shut it down.</li>
</ul></li>
<li>Endpoint Configurations act as blueprints for endpoints:
<ul>
<li>What resources should be used?</li>
<li>What models should be used?</li>
<li>How the incoming data should be split up among deployed models?</li>
</ul></li>
<li>Pro tips on endpoints:
<ul>
<li>Endpoints require serializing - converting the data into something that can be transferred using HTTP. The backend also needs to know how to deserialize the data.</li>
<li>Only entities that are authenticated with AWS can send or receive data from the deployed model. Thus, use an API Gateway to create HTTP endpoints (URL addresses) that are integrated with AWS services and open to the public (charged per execution)</li>
<li>Use Lambda function for pre and post processing, e.g., tokenization (charged per execution)</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Creating a Lambda function</span>

<span class="hljs-keyword">import</span> boto3

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lambda_handler</span><span class="hljs-params">(event, context)</span>:</span>
    runtime = boto3.Session().client(<span class="hljs-string">'sagemaker-runtime'</span>)
    response = runtime.invoke_endpoint(EndpointName = <span class="hljs-string">'**ENDPOINT NAME HERE**'</span>,
                                       ContentType = <span class="hljs-string">'text/plain'</span>,
                                       Body = event[<span class="hljs-string">'body'</span>])
    result = response[<span class="hljs-string">'Body'</span>].read().decode(<span class="hljs-string">'utf-8'</span>)
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">'statusCode'</span> : <span class="hljs-number">200</span>,
        <span class="hljs-string">'headers'</span> : { <span class="hljs-string">'Content-Type'</span> : <span class="hljs-string">'text/plain'</span>, <span class="hljs-string">'Access-Control-Allow-Origin'</span> : <span class="hljs-string">'*'</span> },
        <span class="hljs-string">'body'</span> : result
    }
</code></pre>
<ul>
<li>Common deployment workflow:
<ul>
<li>The user does an action.</li>
<li>The website sends the user data off to an HTTP endpoint, created using API Gateway.</li>
<li>The endpoint acts as an interface to a Lambda function.</li>
<li>The Lambda function processes the data and sends it off to the endpoint using Boto3.</li>
<li>The model performs inference on the data and returns the results to the Lambda function.</li>
<li>The Lambda function returns the results to the original caller using the HTTP endpoint.</li>
<li>Lastly, the website receives the inference results and displays those results to the user.</li>
</ul></li>
</ul>
<p><img width=600 src="/datadocs/assets/load-test-sagemaker-5-2.gif"/>
<center><a href="https://aws.amazon.com/blogs/machine-learning/load-test-and-optimize-an-amazon-sagemaker-endpoint-using-automatic-scaling/" class="credit">Credit</a></center></p>
<ul>
<li>Pro tips:
<ul>
<li>Turn endpoints off when not in use with Lambda.</li>
<li>Use inference pipelines for pre and post processing.</li>
<li>Bring multiple models in a single Docker container.</li>
<li>Consider the size of the data hitting a single endpoint (batch transform?)</li>
<li>One can train the model elsewhere and just host it using SageMaker.</li>
<li>Use streaming for faster training, faster inference and smaller payload size.</li>
<li>Keep the payload small, cache the results in a database.</li>
<li><a href="https://youtu.be/KFuc2KWrTHs">Deploy Your ML Models to Production at Scale</a></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="update-the-model"></a><a href="#update-the-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Update the model</h4>
<ul>
<li>One may be confronted with a new data distribution that is hitting the model.
<ul>
<li>For example, for NLP, the frequency of use of different words could have changed: Maybe there is some new slang that has been introduced or some other artifact of popular culture that has changed the way that people write.</li>
</ul></li>
<li>Once accumulated enough user data, perform data labeling to build the new test dataset.</li>
<li>Health-checking: Validate the model to ensure that it satisfies constraints and is still effective.
<ul>
<li>Such constraints may include accurate predictions, interpretability and costs.</li>
<li>Use batch transform to test the model on the new dataset.</li>
</ul></li>
<li>Re-train the model:
<ul>
<li>Make sure that the new model also performs well on the original data.</li>
</ul></li>
<li>Model comparison:
<ul>
<li>Create an endpoint that sends data to multiple models for an A/B test (using routing)</li>
<li>Use a low-level approach to construct an endpoint configuration.</li>
<li>Do not assume that different models will return data in the same way (JSON or CSV?)</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Deploy a combined endpoint</span>

<span class="hljs-comment"># Create endpoint configuration</span>
combined_endpoint_config_name = <span class="hljs-string">"boston-combined-endpoint-config-"</span> + strftime(<span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span>, gmtime())
combined_endpoint_config_info = session.sagemaker_client.create_endpoint_config(
    EndpointConfigName=combined_endpoint_config_name,
    ProductionVariants=[
        {
            <span class="hljs-string">"InstanceType"</span>: <span class="hljs-string">"ml.m4.xlarge"</span>,
            <span class="hljs-string">"InitialVariantWeight"</span>: <span class="hljs-number">1</span>,
            <span class="hljs-string">"InitialInstanceCount"</span>: <span class="hljs-number">1</span>,
            <span class="hljs-string">"ModelName"</span>: linear_model_name,
            <span class="hljs-string">"VariantName"</span>: <span class="hljs-string">"Linear-Model"</span>
        }, {
            <span class="hljs-string">"InstanceType"</span>: <span class="hljs-string">"ml.m4.xlarge"</span>,
            <span class="hljs-string">"InitialVariantWeight"</span>: <span class="hljs-number">1</span>,
            <span class="hljs-string">"InitialInstanceCount"</span>: <span class="hljs-number">1</span>,
            <span class="hljs-string">"ModelName"</span>: xgb_model_name,
            <span class="hljs-string">"VariantName"</span>: <span class="hljs-string">"XGB-Model"</span>
        }])

<span class="hljs-comment"># Create endpoint</span>
endpoint_name = <span class="hljs-string">"boston-update-endpoint-"</span> + strftime(<span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span>, gmtime())
endpoint_info = session.sagemaker_client.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=combined_endpoint_config_name)
endpoint_dec = session.wait_for_endpoint(endpoint_name)
</code></pre>
<ul>
<li>Ask SageMaker to update the existing endpoint so that it uses the new configuration.
<ul>
<li>SageMaker first deploys the new model and then shuts down the old one (= no downtime)</li>
</ul></li>
</ul>
<pre><code class="hljs css language-py"><span class="hljs-comment"># Example: Update the endpoint</span>

session.sagemaker_client.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=linear_endpoint_config_name)
endpoint_dec = session.wait_for_endpoint(endpoint_name)
</code></pre>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 2019-10-8 by Oleg Polakow</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/datadocs/docs/machine-learning/deployment"><span class="arrow-prev">← </span><span>Deployment</span></a><a class="docs-next button" href="/datadocs/docs/deep-learning/deep-learning"><span>Deep Learning</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#amazon-sagemaker">Amazon SageMaker</a><ul class="toc-headings"><li><a href="#workflow">Workflow</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><div class="brand-box"><div class="brand"><a href="https://www.tum.de/nc/en/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/tum_logo.png" alt="Technical University of Munich" height="45"/></a></div><div class="brand"><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a></div></div><section class="copyright">Copyright © 2019 polakowo.io</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '6642fca03d716a543ac4428d7d20b842',
                indexName: 'polakowo-datadocs',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>