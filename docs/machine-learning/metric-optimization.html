<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Metric Optimization · datadocs</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="- A metric is used to measure the algorithm&#x27;s performance."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Metric Optimization · datadocs"/><meta property="og:type" content="website"/><meta property="og:url" content="https://polakowo.github.io/datadocs/"/><meta property="og:description" content="- A metric is used to measure the algorithm&#x27;s performance."/><meta property="og:image" content="https://polakowo.github.io/datadocs/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://polakowo.github.io/datadocs/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/datadocs/img/favicon.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-142521178-1"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'UA-142521178-1');
            </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/datadocs/js/code-block-buttons.js"></script><script type="text/javascript" src="/datadocs/js/disqus.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/datadocs/js/scrollSpy.js"></script><link rel="stylesheet" href="/datadocs/css/prism.css"/><link rel="stylesheet" href="/datadocs/css/main.css"/><script src="/datadocs/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/datadocs/"><h2 class="headerTitle">datadocs</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/datadocs/docs/machine-learning/linear-models" target="_self">Docs</a></li><li class=""><a href="https://github.com/polakowo/datadocs" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Optimization</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Machine Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/machine-learning">Machine Learning</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Methods</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/linear-models">Linear Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/tree-based-models">Tree-Based Models</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/ensemble-methods">Ensemble Methods</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Features</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/eda">Exploratory Data Analysis</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/feature-engineering">Feature Engineering</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/advanced-features">Advanced Features</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Optimization</h4><ul><li class="navListItem navListItemActive"><a class="navItem" href="/datadocs/docs/machine-learning/metric-optimization">Metric Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/validation-schemes">Validation Schemes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/hyperopt">Hyperparameter Optimization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Competitions</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/competitive-ml">Competitive Machine Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/data-leakages">Data Leakages</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Production</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/production-code">Production Code</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/deployment">Deployment</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/machine-learning/deployment-to-cloud">Deployment to Cloud</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Deep Learning<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/deep-learning">Deep Learning</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/dl-strategy">Deep Learning Strategy</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Fundamentals</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/backpropagation">Backpropagation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/activation-functions">Activation Functions</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/initialization">Initialization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/optimization">Optimization</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/regularization">Regularization</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Computer Vision</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnns">Convolutional Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/cnn-architectures">CNN Architectures</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/object-detection">Object Detection</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/face-recognition">Face Recognition</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nst">Neural Style Transfer</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Natural Language Processing</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/rnns">Recurrect Neural Networks</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/word-embeddings">Word Embeddings</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/nmt">Neural Machine Translation</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/attention-mechanisms">Attention Mechanisms</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/deep-learning/speech-recognition">Speech Recognition</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Big Data<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/big-data">Big Data</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-warehousing">Data Warehousing</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-lakes">Data Lakes</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-pipelines">Data Pipelines</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Databases</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/database-design">Database Design</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/sql-databases">SQL Databases</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/wide-column-stores">Wide Column Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/key-value-stores">Key Value Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/document-stores">Document Stores</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/graph-stores">Graph Stores</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Hadoop</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/hadoop">Hadoop Ecosystem</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-ingestion">Data Ingestion</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-storage">Data Storage</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/data-processing">Data Processing</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/query-engines">Query Engines</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/big-data/cluster-management">Cluster Management</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Cloud<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">General</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/cloud-computing">Cloud Computing</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Amazon Web Services</h4><ul><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-compute">Compute</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-storage">Storage</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-databases">Databases</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-security">Security</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-networking">Networking</a></li><li class="navListItem"><a class="navItem" href="/datadocs/docs/cloud/aws-management">Management</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/polakowo/datadocs/edit/master/docs/machine-learning/metric-optimization.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 class="postHeaderTitle">Metric Optimization</h1></header><article><div><span><ul>
<li>A metric is used to measure the algorithm's performance.</li>
<li>A loss function is used to optimize an algorithm.</li>
<li>If a metric is not optimizable:
<ul>
<li>Preprocess train and optimize another metric.</li>
<li>Optimize another metric and postprocess predictions.</li>
<li>Write a custom loss function.</li>
<li>Optimize another metric and use early stopping.</li>
</ul></li>
<li><a href="https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234">Metrics to Evaluate your Machine Learning Algorithm</a></li>
<li><a href="https://www.kdnuggets.com/2018/04/right-metric-evaluating-machine-learning-models-1.html">Choosing the Right Metric for Evaluating Machine Learning Models</a></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="tips"></a><a href="#tips" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tips</h4>
<ul>
<li><a href="https://www.pyimagesearch.com/2019/10/14/why-is-my-validation-loss-lower-than-my-training-loss/">Why is my validation loss lower than my training loss?</a>
<ul>
<li>Regularization applied during training, but not during validation/testing.</li>
<li>Training loss is measured during each epoch while validation loss is measured after each epoch.</li>
<li>The validation set may be easier than the training set.</li>
</ul></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="regression-metrics"></a><a href="#regression-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Regression metrics</h2>
<ul>
<li>MSE, RMSE and R-squared are similar from the optimization perspective.</li>
<li>Do you have outliers (mistakes, measurement errors)? Use MAE</li>
<li>Do you have unexpected values you should care about? Use (R)MSE</li>
<li>MSPE and MAPE are sensitive to relative errors and can be thought as weighted versions of MSE and MAE, respectively.
<ul>
<li>Relative errors are intended to be both independent of scale and usable on all scales.</li>
<li>They are mainly used as forecast accuracy measures in time-series data.</li>
<li><a href="https://pdfs.semanticscholar.org/435e/b6e05fcda264c8c1e7fbcdee7116bb5b1424.pdf">A Survey of Forecast Error Measures</a></li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="mse-based-metrics"></a><a href="#mse-based-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MSE-based metrics</h3>
<h4><a class="anchor" aria-hidden="true" id="mse"></a><a href="#mse" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MSE</h4>
<p>$$\large{MSE=\frac{1}{n}\sum_{i=1}^{n}{(y_i-\hat{y}_i)^2}}$$</p>
<ul>
<li>Mean Squared Error (MSE) measures the average squared difference between the estimated values and what is estimated.</li>
<li>Can range from 0 to \(\infty\) and are indifferent to the direction of errors.</li>
<li>It is a negatively-oriented score, which means lower values are better.</li>
<li>Useful if there are any unexpected values that we should care about.</li>
<li>MSE is one of the most widely used loss functions because of its ability to partition the variation in a dataset into variation explained by the model and variation explained by randomness.</li>
<li>Limitations:
<ul>
<li>The least useful metric because of the lack of interpretability.</li>
<li>MSE has the disadvantage of heavily weighting outliers.
$$MSE(30, 20)=100$$
$$MSE(30000, 20000)=100000000$$</li>
<li>Results in a particularly problematic behaviour if applied on noisy data: a single bad prediction may skew the metric towards underestimating the model's quality; if errors are smaller than one, the opposite effect takes place.</li>
</ul></li>
<li>Best constant: mean</li>
<li>Loss function:
<ul>
<li>MSE can be directly optimized and is implemented by most libraries.</li>
<li>Synonyms: <em>L2 Loss</em></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="rmse"></a><a href="#rmse" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>RMSE</h4>
<p>$$\large{RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}{(y_i-\hat{y}_i)^2}}}$$</p>
<ul>
<li>Root Mean Square Error (RMSE) is introduced to make scale of the errors to be the same as the scale of targets.</li>
<li>Expresses average model prediction error in units of the variable of interest.</li>
<li>Every minimizer of MSE is also a minimizer for RMSE and vice versa, since the square root is an non-decreasing function.</li>
<li>Even though RMSE and MSE are similar in terms of optimization, they are not interchangeable for gradient-based methods: Travelling along RMSE gradient is equivalent to traveling along MSE gradient but with a different flowing rate.</li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="r-msle"></a><a href="#r-msle" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>(R)MSLE</h4>
<p>$$\large{L(y,\hat{y})=\frac{1}{n}\sum_{i=0}^{n}{(\log{(y_i+1)}-\log{(\hat{y}_i+1)})^2}}$$</p>
<ul>
<li>Mean Squared Logarithmic Error (MSLE) is MSE calculated on logarithmic scale.</li>
<li>The introduction of the logarithm makes MSLE only care about the relative difference between predictions and target.</li>
</ul>
<p>$$MSLE(30, 20)=0.02861$$
$$MSLE(30000, 20000)=0.03100$$</p>
<ul>
<li>Used in cases where the range of the target value is large (e.g., in forecasting).</li>
</ul>
<p><center><img width=200 src="/datadocs/assets/1m_small.gif.png"/></center></p>
<ul>
<li>The targets are usually non-negative but can equal to 0 - add a tiny constant before applying log.</li>
<li>RMSLE is considered as a better metric than MAPE, since it is less biased towards smaller targets.</li>
<li>Best constant: weighted mean in log space (weights are values themselves)</li>
<li>Loss function:
<ul>
<li>Transform target with \(z_i=\log{y_i+1}\)</li>
<li>Fit a model with MSE loss</li>
<li>Transform predictions back with \(\hat{y_i}=\exp{\hat{z_i}}-1\)</li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="r-squared"></a><a href="#r-squared" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>R squared</h4>
<p>$$\large{R^2=1-\frac{SS_{\text{RES}}}{SS_{\text{TOT}}}=\frac{\sum_i{(y_i-\hat{y}_i)^2}}{\sum_i{(y_i-\overline{y}_i)^2}}}$$</p>
<ul>
<li>The coefficient of determination, or \(R^2\) measures how much the model is better than the naive MSE baseline.</li>
<li>The MSE baseline can be thought of as the MSE that the simplest possible model would get.</li>
<li>Has the advantage of being scale-free (values between \(-\infty\) and \(1\)).</li>
<li>Values outside the range can occur when the model fits the data worse than the baseline.</li>
<li>Limitations:
<ul>
<li>R-squared cannot determine whether the coefficient estimates and predictions are biased.</li>
<li>Low values are not inherently bad for harder-to-predict data while high values do not necessarily indicate that the model has a good fit.</li>
<li>\(R^2\) will never decrease as variables are added and will probably experience an increase due to randomness. The adjusted R-squared can solve this by increasing only if the new term improves the model more than would be expected by chance.</li>
</ul></li>
<li>Best constant: mean</li>
<li>Loss function:
<ul>
<li>RMSE or MSE loss should be used instead.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="mae-based-metrics"></a><a href="#mae-based-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MAE-based metrics</h3>
<h4><a class="anchor" aria-hidden="true" id="mae"></a><a href="#mae" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MAE</h4>
<p>$$\large{MAE=\frac{\sum_{i=1}^{n}{|y_i-\hat{y}_i|}}{n}}$$</p>
<ul>
<li>MAE measures the average magnitude of the errors in a set of predictions, without considering their direction.</li>
<li>Expresses average model prediction error in units of the variable of interest.</li>
<li>Can range from 0 to \(\infty\) and are indifferent to the direction of errors.</li>
<li>It is a negatively-oriented score, which means lower values are better.</li>
<li>The individual differences are weighted equally.</li>
<li>MAE loss is useful if the training data is corrupted with outliers.</li>
<li>It is widely used in finance, where error 10 is exactly two times worse than error 5.</li>
<li>If the absolute value is not taken, the average error becomes the Mean Bias Error (MBE).</li>
<li>Best constant: median (more robust to outliers than mean)</li>
<li>Loss function:
<ul>
<li>MAE can be directly optimized but is implemented by fewer libraries.</li>
<li>Not differentable when predictions are equal to target (rare case)</li>
<li>One big problem in using MAE loss (for neural nets especially) is that its gradient will be large even for small loss values. Here helps a dynamic learning rate which decreases as we move closer to the minima.</li>
<li>MAE criterion is slower than MSE criterion</li>
<li>Synonyms: <em>L1 Loss, Median regression</em></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="mae-vs-rmse"></a><a href="#mae-vs-rmse" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MAE vs. RMSE</h4>
<ul>
<li>RMSE has a tendency to be increasingly larger than MAE as the test sample size increases.</li>
<li>RMSE has the benefit of penalizing large errors more.</li>
<li>MAE is the most robust choice in respect to outliers.</li>
<li>MAE is shown to be an unbiased estimator while RMSE is a biased estimator.</li>
<li>Loss functions:
<ul>
<li>L1 loss is more robust to outliers, but its derivatives are not continuous, making it inefficient to find the solution.</li>
<li>L2 loss is sensitive to outliers, but gives a more stable and closed form solution (by setting its derivative to 0.)</li>
<li><a href="http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/">Comparing the performance using L1 loss and L2 loss</a></li>
<li>As option: Huber loss combines good properties from both MSE and MAE.</li>
<li>As another option: Log-Cosh loss has all the advantages of Huber loss, and it’s twice differentiable everywhere (which is more favorable for models using Newton’s method), unlike Huber loss.
<center><img width=400 src="/datadocs/assets/vXMgz.png"/></center>
<center><a href="https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0" class="credit">Credit</a></center></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="mape"></a><a href="#mape" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MAPE</h4>
<p>$$\large{MAPE=100\frac{1}{n}\sum_{i=1}^{n}{\frac{|y_i-\hat{y}_i|}{y_i}}}$$</p>
<ul>
<li>Mean Absolute Percentage Error (MAPE) or Mean Absolute Deviation (MAD) is relative MAE (in %).</li>
<li>MAPE is often preferred because apparently managers understand percentages better than squared errors.</li>
<li>It is also commonly used as a loss function for regression problems and in model evaluation because of easy interpretation.</li>
<li>MAPEs greater than 100% can occur.</li>
<li>Limitations:
<ul>
<li>MAPE is biased towards smaller targets which yield higher errors.</li>
<li>MAPE can't be used for values where divisions and ratios make no sense (temperature scales).</li>
<li>RMSE method is more accurate and recent.</li>
</ul></li>
<li>Best constant: weighted median</li>
<li>Loss function:
<ul>
<li>Use weights for samples (<code>sample_weight</code>) and optimize MAE.</li>
<li>Or resample the dataset beforehand (<code>df.sample</code>) and optimize MAE.</li>
<li>Usually need to resample many times and average.</li>
</ul></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="classification-metrics"></a><a href="#classification-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Classification metrics</h2>
<ul>
<li>Logloss is the only metric that is easy to optimize directly.</li>
<li>For a binary classification task, fit any metric, and tune with the binarization threshold.</li>
<li>For multi-class tasks, fit any metric and tune parameters comparing the models by their accuracy score (not optimization metric).</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="accuracy"></a><a href="#accuracy" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Accuracy</h3>
<p>$$\large{Accuracy=\frac{1}{n}\sum_{i=1}^{n}{[y_i=\hat{y}_i]}}$$</p>
<ul>
<li>Accuracy is the ratio of number of correct predictions to the total number of input samples.</li>
<li>Works well for balanced datasets (one can get a nearly perfect score with imbalanced data classes).</li>
<li>To compute accuracy we need hard predictions, that is, apply a threshold.</li>
<li>The optimal threshold can be found with grid search.</li>
<li>Best constant: the most frequent class</li>
<li>Loss function:
<ul>
<li>The loss function is not differentable since gradients are zero almost always.</li>
<li>Zero-one loss may be approximated with a proxy loss such as logloss or Hinge loss.
<center><img width=400 src="/datadocs/assets/RUIJ4.png"/></center>
<center><a href="https://stackoverflow.com/questions/47716601/classification-modified-huber-loss-how-is-it-more-tolerant-to-outliers" class="credit">Credit</a></center></li>
</ul></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="dealing-with-imbalanced-data"></a><a href="#dealing-with-imbalanced-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dealing with imbalanced data</h4>
<ul>
<li>Resampling:
<ul>
<li>Undersampling: sample from the majority class</li>
<li>Oversampling: replicate points from the minority class</li>
<li>Consider testing random and non-random (e.g., stratified) sampling schemes.</li>
<li>Consider testing different resampled ratios.</li>
</ul></li>
<li>Generating synthetic data: create new synthetic points from the minority class or both classes (see SMOTE).</li>
<li>But information about class distribution is lost when resampling the dataset and can skew predictions on test.</li>
<li>Penalize mistakes on minority classes with class re-weighting (<code>sample_weight</code>).</li>
<li>Use a different performance metric (e.g., precision, recall, F-score, ROC AUC).</li>
<li><a href="https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba">What metrics should be used for evaluating a model on an imbalanced data set?</a></li>
<li><a href="https://nbviewer.jupyter.org/github/awslabs/amazon-sagemaker-examples/blob/master/scientific_details_of_algorithms/linear_learner_class_weights_loss_functions/linear_learner_class_weights_loss_functions.ipynb">Hands-on example: Detecting credit card fraud</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="logloss"></a><a href="#logloss" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>LogLoss</h3>
<p>$$\large{LogLoss=-\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{n}{y_{i,j}\log{\hat{y}_{i,j}}}}$$</p>
<ul>
<li>Logarithmic loss, or logloss, increases as the predicted probability diverges from the actual label.</li>
<li>For all samples, enforces the model to assign a probability to be of a certain class.</li>
<li>To ensure numeric stability, predictions are clipped to be from \([10^{-15}, 1-10^{-15}]\) instead of \([0, 1]\).</li>
<li>Logloss has no upper bound (\([0, \infty)\)) with smaller values indicating a better fit.</li>
<li>Best constant: class frequency as vector</li>
<li>Loss function:
<ul>
<li>Logloss can be directly optimized and is implemented by most libraries.</li>
<li>NNs at default optimize logloss for classification.</li>
<li>Random forest classifiers are bad at logloss and produce rather conservative predictions. RFs can be calibrated in several ways: 1) Platt scaling (fit logistic regression to predictions), 2) isotonic regression, and 3) stacking.</li>
<li>Calibrated classifiers (rarely the case) will return posterior probabilities where threshold 0.5 would be optimal.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="auc"></a><a href="#auc" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>AUC</h3>
<ul>
<li>Area under the ROC Curve (AUC) of a classifier is a performance measurement for classification problem at various thresholds settings.</li>
<li>AUC tells how much model is capable of distinguishing between classes 0 and 1.</li>
</ul>
<p><center><img width=350 src="/datadocs/assets/glucosedistn.png"/></center>
<center><a href="http://corysimon.github.io/articles/what-is-an-roc-curve/" class="credit">Credit</a></center></p>
<ul>
<li>AUC is a rank-based metric (depends on ordering of predictions, not on absolute values)</li>
<li>Used for binary classification problems.
<ul>
<li>For multi-class tasks, we can plot \(N\) number of AUC-ROC curves for \(N\) number classes using one-vs-all methodology.</li>
</ul></li>
<li>Good for cases when you need to estimate how well your model is at discriminating TRUE from FALSE values.</li>
<li>Removes the need for hard predictions and dependency on the threshold.</li>
<li>AUC can be obtained in different ways:
<ul>
<li>Area under the curve of plot FPR (\(\frac{TP}{TP+FN}\)) vs TPR (\(\frac{FP}{FP+TN}\)) at different points in \([0, 1]\) (<a href="http://www.navan.name/roc/">Understanding ROC curves</a>)</li>
<li>The probability of a pair of the predictions to be ordered in the right way.</li>
<li>The expectation that the classifier will rank a randomly chosen positive higher than a randomly chosen negative.</li>
</ul></li>
<li>Best constant: any constant, random predictions lead to \(AUC=0.5\)</li>
<li>Loss function:
<ul>
<li>Although the loss function of AUC has zero gradients almost everywhere, exactly as accuracy loss, there exists an algorithm to optimize AUC with gradient-based methods, which use pair-wise loss instead of point-wise loss (supported by LGBM, XGBoost).</li>
<li>XGBoost learned with logloss gives a comparable AUC score.</li>
</ul></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="cohens-kappa"></a><a href="#cohens-kappa" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cohen's Kappa</h3>
<p>$$\large{\kappa=1-\frac{1-p_{\text{observed}}}{1-p_{\text{chance}}}}$$</p>
<ul>
<li>The kappa statistic is a metric that compares an observed accuracy with an expected accuracy (random chance). An accuracy of 80% is a lot more impressive with an expected accuracy of 50% versus an expected accuracy of 75%.</li>
<li>It is used not only to evaluate a single classifier, but also to evaluate classifiers amongst themselves.</li>
<li>Outputs 0 for baseline accuracy and 1 for excelent accuracy.</li>
<li>The more complex (and random) the dataset is, the lower kappa will be considered as high enough (such as 0.4)</li>
<li>Similar to how R squared better scales the MSE values for being easier explained.</li>
<li>Kappa is quite intuitive for medicine applications: how much the model agrees with professional doctors?</li>
<li>Best constant: the most frequent class</li>
<li>Loss function:
<ul>
<li>Treat this task as a regression problem (but more complex than MSE) and post-process the predictions by rounding them with a (tuned) threshold (if we relax the predictions to take values between the labels).</li>
<li><a href="https://arxiv.org/abs/1509.07107">Or implement &quot;soft kappa&quot; loss</a></li>
</ul></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="ranking-metrics"></a><a href="#ranking-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Ranking metrics</h2>
<ul>
<li><a href="http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf">Learning to Rank using Gradient Descent</a> -- original paper about pairwise method for AUC optimization</li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf">Overview of further developments of RankNet</a></li>
<li><a href="https://sourceforge.net/p/lemur/wiki/RankLib/">RankLib (implementations for the 2 papers from above)</a></li>
<li><a href="https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview">Learning to Rank Overview</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="clustering-metrics"></a><a href="#clustering-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Clustering metrics</h2>
<ul>
<li><a href="http://nlp.uned.es/docs/amigo2007a.pdf">Evaluation metrics for clustering</a></li>
<li><a href="https://www.kaggle.com/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering">Unsupervised learning: PCA and clustering</a></li>
</ul>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 2019-10-15 by Oleg Polakow</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/datadocs/docs/machine-learning/advanced-features"><span class="arrow-prev">← </span><span>Advanced Features</span></a><a class="docs-next button" href="/datadocs/docs/machine-learning/validation-schemes"><span>Validation Schemes</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#regression-metrics">Regression metrics</a><ul class="toc-headings"><li><a href="#mse-based-metrics">MSE-based metrics</a></li><li><a href="#mae-based-metrics">MAE-based metrics</a></li></ul></li><li><a href="#classification-metrics">Classification metrics</a><ul class="toc-headings"><li><a href="#accuracy">Accuracy</a></li><li><a href="#logloss">LogLoss</a></li><li><a href="#auc">AUC</a></li><li><a href="#cohens-kappa">Cohen's Kappa</a></li></ul></li><li><a href="#ranking-metrics">Ranking metrics</a></li><li><a href="#clustering-metrics">Clustering metrics</a></li></ul></nav></div><footer class="nav-footer" id="footer"><div class="brand-box"><div class="brand"><a href="https://www.tum.de/nc/en/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/tum_logo.png" alt="Technical University of Munich" height="45"/></a></div><div class="brand"><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="brand-link"><img src="/datadocs/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a></div></div><section class="copyright">Copyright © 2019 polakowo.io</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '6642fca03d716a543ac4428d7d20b842',
                indexName: 'polakowo-datadocs',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>